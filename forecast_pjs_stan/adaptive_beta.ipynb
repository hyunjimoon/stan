{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from aria.models.pooling import PoolingModel\n",
    "import matplotlib.pyplot as plt\n",
    "from fbprophet import Prophet\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "import os\n",
    "def smape(a, b):\n",
    "    return np.mean(np.abs(a - b) / ((np.abs(a) + np.abs(b)) / 2))\n",
    "\n",
    "def mape(a, b):\n",
    "    return np.mean(np.abs(a - b) / (np.abs(a)))\n",
    "\n",
    "def mse(a,b):\n",
    "    return np.square(np.subtract(a,b)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, min, max, size):\n",
    "    # y = C / 1 + e ^-Bx- size/2) \n",
    "    # min, max를 가지며, (size/2, (min + max)/2)를 지남. B는 growth rate로 클수록 비균일증가(1설정시 shape커지면 직선 - >1/(max-min))\n",
    "    # B로 적절한 값은? 가져야할 성질? (미분해서 B 설정)\n",
    "    B = (max - min) / (max + min)**2\n",
    "    return (max - min) / (1 + np.exp(-B * (x - size / 2))) + min\n",
    "\n",
    "def info_gain(df, beta_min, beta_max):\n",
    "    return [sigmoid(i, beta_min, beta_max, df.shape[0]) for i in range(df.shape[0])]\n",
    "\n",
    "def cutoff_fit_q(df, i):\n",
    "    df = df.copy()\n",
    "#     print(\"cutoff: \",  df.loc[df['y'] > np.quantile(df.y,i), 'y'].shape[0])\n",
    "    df.loc[df['y'] > np.quantile(df.y,i), 'y'] = None\n",
    "\n",
    "\n",
    "    m = PoolingModel()\n",
    "    m.add_seasonality(7, 3)\n",
    "\n",
    "    m.fit(df)\n",
    "    return m\n",
    "\n",
    "def cutoff_fit(df, i):\n",
    "    df = df.copy()\n",
    "\n",
    "    u, s = np.mean(df['y']), np.std(df['y'])\n",
    "#     print(\"cutoff: \", df.loc[df['y'] - u > i* s, 'y'].shape[0])\n",
    "    df.loc[df['y'] - u > i* s, 'y'] = None\n",
    "\n",
    "    m = PoolingModel()\n",
    "    m.add_seasonality(7, 3)\n",
    "    \n",
    "    if df.shape[0] < 14:\n",
    "        m = PoolingModel()\n",
    "        m.add_seasonality(7, 3)\n",
    "    elif df.shape[0] < 365: \n",
    "        m = PoolingModel()\n",
    "        m.add_seasonality(7, 3)\n",
    "        m.add_seasonality(30.4375, 5)\n",
    "    else:\n",
    "        m = PoolingModel()\n",
    "        m.add_seasonality(7, 3)\n",
    "        m.add_seasonality(30.4375, 5)\n",
    "        m.add_seasonality(365.25, 10)\n",
    "    m.fit(df)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(rn, df, dev_avg, beta_min, beta, beta_max , q_min, q_max):\n",
    "    rng = np.random.RandomState(rn) # 0,1,2\n",
    "    true_dev = rng.normal(dev_avg, 0.5) \n",
    "#     print(\"true_dev:\", true_dev)\n",
    "    \n",
    "    ol_cnt = int(df.shape[0]*0.05)\n",
    "    ol_date = rng.choice(df['ds'],ol_cnt)\n",
    "    df['y'].iloc[np.where(df['ds'].isin(ol_date))[0]] *= true_dev\n",
    "    \n",
    "    yms = [(y,m) for y in np.unique(df.ds.dt.year) for m in np.unique(df.ds.dt.month)]\n",
    "    \n",
    "    errors = list()\n",
    "    errors_cutoff = list()\n",
    "    errors_adap_cutoff = list()\n",
    "    errors_cutoff_q = list()\n",
    "    errors_adap_cutoff_q = list()\n",
    "    \n",
    "    errors_lst = list()\n",
    "    errors_cutoff_lst = list()\n",
    "    errors_adap_cutoff_lst = list()\n",
    "    errors_cutoff_q_lst  = list()\n",
    "    errors_adap_cutoff_q_lst = list()\n",
    "    \n",
    "    gains = info_gain(df, beta_min, beta_max)\n",
    "\n",
    "    history = df[(df['ds'].dt.year == df.ds.dt.year.iloc[0]) & (df['ds'].dt.month  ==  df.ds.dt.month.iloc[0])]\n",
    "    \n",
    "    for i, ym_i in enumerate(range(len(yms) - 1)):\n",
    "        \n",
    "        future = df[(df['ds'].dt.year == yms[ym_i + 1][0]) & (df['ds'].dt.month == yms[ym_i + 1][1])] \n",
    "        tf = pd.concat([history, future]).reset_index().copy()\n",
    "        \n",
    "        # \n",
    "        m = cutoff_fit(history, 100)\n",
    "        tf['yhat_1'] = m.predict(tf)['yhat']\n",
    "        error = smape(tf.y[-30:],tf.yhat_1[-30:])\n",
    "        errors.append(error)\n",
    "\n",
    "        #\n",
    "        m = cutoff_fit(history, beta)\n",
    "        tf['yhat_2'] = m.predict(tf)['yhat']\n",
    "        error = smape(tf.y[-30:],tf.yhat_2[-30:])\n",
    "        errors_cutoff.append(error)\n",
    "        \n",
    "        #\n",
    "        beta = info_gain(df, beta_min, beta_max)[::-1][i * 30 - 1]\n",
    "        m = cutoff_fit(history, beta)\n",
    "        tf['yhat_3'] = m.predict(tf)['yhat']\n",
    "        error = smape(tf.y[-30:],tf.yhat_3[-30:])\n",
    "        errors_adap_cutoff.append(error)\n",
    "\n",
    "        #\n",
    "        m = cutoff_fit_q(history, 0.95)\n",
    "        tf['yhat_4'] = m.predict(tf)['yhat']\n",
    "        error = smape(tf.y[-30:],tf.yhat_4[-30:])\n",
    "        errors_cutoff_q.append(error)\n",
    "        \n",
    "        #\n",
    "        q = info_gain(df, q_min, q_max)[::-1][i * 30 - 1]\n",
    "        m = cutoff_fit_q(history, q)\n",
    "        tf['yhat_5'] = m.predict(tf)['yhat']\n",
    "        error = smape(tf.y[-30:],tf.yhat_5[-30:])\n",
    "        errors_adap_cutoff_q.append(error)\n",
    "        \n",
    "        history = pd.concat([history, future])\n",
    "        \n",
    "        \n",
    "#         fig, ax = plt.subplots()\n",
    "#         tf[['y', 'yhat_1', 'yhat_2',  'yhat_3','yhat_4',  'yhat_5',]].plot(ax = ax)\n",
    "        \n",
    "#         print(\"without cutoff: \", np.mean(errors))\n",
    "#         print(\"fixed beta: \", np.mean(errors_cutoff))\n",
    "#         print(\"adaptive: \", np.mean(errors_adap_cutoff))\n",
    "#         print(\"q: \", np.mean(errors_cutoff_q))\n",
    "#         print(\"adap_q: \", np.mean(errors_adap_cutoff_q))\n",
    "        \n",
    "        errors_lst.append(np.mean(errors))\n",
    "        errors_cutoff_lst.append(np.mean(errors_cutoff))\n",
    "        errors_adap_cutoff_lst.append(np.mean(errors_adap_cutoff))\n",
    "        errors_cutoff_q_lst.append(np.mean(errors_cutoff_q))\n",
    "        errors_adap_cutoff_q_lst.append(np.mean(errors_adap_cutoff_q))\n",
    "        \n",
    "    print(\"without cutoff: \", np.mean(errors_lst), np.std(errors_lst))\n",
    "    print(\"fixed beta: \", np.mean(errors_cutoff_lst), np.std(errors_cutoff_lst))\n",
    "    print(\"adaptive: \", np.mean(errors_adap_cutoff_lst), np.std(errors_adap_cutoff_lst))\n",
    "    print(\"q\", np.mean(errors_cutoff_q_lst), np.std(errors_cutoff_q_lst))\n",
    "    print(\"adap_q\", np.mean(errors_adap_cutoff_q_lst), np.std(errors_adap_cutoff_q_lst))\n",
    "    return np.mean(errors_lst), np.mean(errors_cutoff_lst), np.mean(errors_adap_cutoff_lst), np.mean(errors_cutoff_q_lst), np.mean(errors_adap_cutoff_q_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depending on sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1milk.csv\n",
      "without cutoff:  0.8792529730722618 0.0\n",
      "fixed beta:  0.5449860696407706 0.0\n",
      "adaptive:  0.5449860696407706 0.0\n",
      "q 0.46327642297128463 0.0\n",
      "adap_q 0.46327642297128463 0.0\n",
      "without cutoff:  0.9020487442400493 0.0\n",
      "fixed beta:  0.8516837976094486 0.0\n",
      "adaptive:  0.8516837976094486 0.0\n",
      "q 0.35551927003164 0.0\n",
      "adap_q 0.35551927003164 0.0\n",
      "without cutoff:  2.0 0.0\n",
      "fixed beta:  0.8742985545953338 0.0\n",
      "adaptive:  0.8742985545953338 0.0\n",
      "q 0.3624543415004179 0.0\n",
      "adap_q 0.3624543415004179 0.0\n",
      "without cutoff:  1.6200278849251493 0.0\n",
      "fixed beta:  1.6348497053521431 0.0\n",
      "adaptive:  1.6348497053521431 0.0\n",
      "q 0.5224334647117237 0.0\n",
      "adap_q 0.5224334647117237 0.0\n",
      "without cutoff:  1.7330650912964174 0.0\n",
      "fixed beta:  2.0 0.0\n",
      "adaptive:  2.0 0.0\n",
      "q 0.5647671640374747 0.0\n",
      "adap_q 0.5647671640374747 0.0\n",
      "without cutoff:  2.0 0.0\n",
      "fixed beta:  1.1670434423682694 0.0\n",
      "adaptive:  1.1670434423682694 0.0\n",
      "q 0.6406334670287882 0.0\n",
      "adap_q 0.6406334670287882 0.0\n",
      "without cutoff:  1.3847076062476267 0.0\n",
      "fixed beta:  1.4991800031562181 0.0\n",
      "adaptive:  1.6434656763590045 0.0\n",
      "q 0.45475795611584935 0.0\n",
      "adap_q 0.45475795611584935 0.0\n",
      "without cutoff:  1.4139329186662835 0.0\n",
      "fixed beta:  1.5163996579742103 0.0\n",
      "adaptive:  1.6034643751086777 0.0\n",
      "q 0.5166838286956422 0.0\n",
      "adap_q 0.5166838286956422 0.0\n",
      "without cutoff:  1.3868503587066325 0.0\n",
      "fixed beta:  1.5181128919487226 0.0\n",
      "adaptive:  1.5531989290465327 0.0\n",
      "q 0.5673536442407399 0.0\n",
      "adap_q 0.5673536442407399 0.0\n",
      "without cutoff:  1.2885207801314777 0.0\n",
      "fixed beta:  1.373104130948757 0.0\n",
      "adaptive:  1.373104130948757 0.0\n",
      "q 0.6667514576790069 0.0\n",
      "adap_q 0.6667514576790069 0.0\n",
      "\n",
      " ====================================\n",
      "2logistics.csv\n",
      "without cutoff:  1.1554933108987526 0.0\n",
      "fixed beta:  0.7217272836666863 0.0\n",
      "adaptive:  0.7217272836666863 0.0\n",
      "q 0.3177956494335428 0.0\n",
      "adap_q 0.3177956494335428 0.0\n",
      "without cutoff:  1.2196451035675333 0.0\n",
      "fixed beta:  0.7081802641753988 0.0\n",
      "adaptive:  0.7081802641753988 0.0\n",
      "q 0.3432095801164572 0.0\n",
      "adap_q 0.3432095801164572 0.0\n",
      "without cutoff:  1.0421071095926946 0.0\n",
      "fixed beta:  0.7695222565131586 0.0\n",
      "adaptive:  0.8724783370695388 0.0\n",
      "q 1.471634334978179 0.0\n",
      "adap_q 1.471634334978179 0.0\n",
      "without cutoff:  1.1368396304657262 0.0\n",
      "fixed beta:  1.0404353595670706 0.0\n",
      "adaptive:  0.9468270879099173 0.0\n",
      "q 0.8888742841639813 0.0\n",
      "adap_q 0.8888742841639813 0.0\n",
      "without cutoff:  1.0574614426406082 0.0\n",
      "fixed beta:  1.1187491170315949 0.0\n",
      "adaptive:  1.1187491170315949 0.0\n",
      "q 0.9213490411492915 0.0\n",
      "adap_q 0.9213490411492915 0.0\n",
      "without cutoff:  0.9598828521809932 0.0\n",
      "fixed beta:  1.1999546144097348 0.0\n",
      "adaptive:  1.3641907604575434 0.0\n",
      "q 0.9938007960355448 0.0\n",
      "adap_q 0.9938007960355448 0.0\n",
      "without cutoff:  0.9617193056974911 0.0\n",
      "fixed beta:  0.9640418559815555 0.0\n",
      "adaptive:  0.9746123109325686 0.0\n",
      "q 0.7652025052831012 0.0\n",
      "adap_q 0.7652025052831012 0.0\n",
      "without cutoff:  0.9528575411885333 0.0\n",
      "fixed beta:  0.9714965923231252 0.0\n",
      "adaptive:  1.0207668751466776 0.0\n",
      "q 0.8071568930236752 0.0\n",
      "adap_q 0.8071568930236752 0.0\n",
      "without cutoff:  0.9528359589936959 0.0\n",
      "fixed beta:  0.9741698071786149 0.0\n",
      "adaptive:  1.0904013457084354 0.0\n",
      "q 0.8873549739062336 0.0\n",
      "adap_q 0.8873549739062336 0.0\n",
      "without cutoff:  1.0871571986499318 0.0\n",
      "fixed beta:  1.330577621393323 0.0\n",
      "adaptive:  1.330577621393323 0.0\n",
      "q 1.0247866764160316 0.0\n",
      "adap_q 1.0247866764160316 0.0\n",
      "\n",
      " ====================================\n",
      "3miltary.csv\n",
      "without cutoff:  1.5685018039151084 0.0\n",
      "fixed beta:  1.3057253693127175 0.0\n",
      "adaptive:  1.3057253693127175 0.0\n",
      "q 0.5961606772795333 0.0\n",
      "adap_q 0.5961606772795333 0.0\n",
      "without cutoff:  1.4908100026907312 0.0\n",
      "fixed beta:  1.5175092007618516 0.0\n",
      "adaptive:  1.5175092007618516 0.0\n",
      "q 0.6269458601524125 0.0\n",
      "adap_q 0.6269458601524125 0.0\n",
      "without cutoff:  2.0 0.0\n",
      "fixed beta:  0.9345383850015316 0.0\n",
      "adaptive:  0.9345383850015316 0.0\n",
      "q 1.7002383720072023 0.0\n",
      "adap_q 1.7002383720072023 0.0\n",
      "without cutoff:  1.8588517579190522 0.0\n",
      "fixed beta:  1.2933716708533607 0.0\n",
      "adaptive:  1.2933716708533607 0.0\n",
      "q 1.691254289843801 0.0\n",
      "adap_q 1.691254289843801 0.0\n",
      "without cutoff:  1.8532303585102072 0.0\n",
      "fixed beta:  1.073157434369507 0.0\n",
      "adaptive:  1.073157434369507 0.0\n",
      "q 1.3467783519731364 0.0\n",
      "adap_q 1.3467783519731364 0.0\n",
      "without cutoff:  1.8902519592861835 0.0\n",
      "fixed beta:  1.7820992202985737 0.0\n",
      "adaptive:  1.1877824838047375 0.0\n",
      "q 1.2376244452162517 0.0\n",
      "adap_q 1.2376244452162517 0.0\n",
      "without cutoff:  1.7693300562804561 0.0\n",
      "fixed beta:  2.0 0.0\n",
      "adaptive:  2.0 0.0\n",
      "q 0.6890198266675249 0.0\n",
      "adap_q 0.6890198266675249 0.0\n",
      "without cutoff:  1.8184035754133212 0.0\n",
      "fixed beta:  2.0 0.0\n",
      "adaptive:  2.0 0.0\n",
      "q 0.712554156296305 0.0\n",
      "adap_q 0.712554156296305 0.0\n",
      "without cutoff:  1.830218069903346 0.0\n",
      "fixed beta:  2.0 0.0\n",
      "adaptive:  2.0 0.0\n",
      "q 0.7741649297692326 0.0\n",
      "adap_q 0.7741649297692326 0.0\n",
      "without cutoff:  1.9552187433022634 0.0\n",
      "fixed beta:  2.0 0.0\n",
      "adaptive:  2.0 0.0\n",
      "q 0.8928878547436462 0.0\n",
      "adap_q 0.8928878547436462 0.0\n",
      "\n",
      " ====================================\n",
      "without cutoff:  1.4389740712794177 0.3879109823313107\n",
      "fixed beta:  1.2894971435477227 0.42961870491281007\n",
      "adaptive:  1.2902230076208108 0.42077487914498374\n",
      "q 0.7934474838489217 0.37139814474794725\n",
      "adap_q 0.7934474838489217 0.37139814474794725\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './data/'\n",
    "fnames = sorted(os.listdir(DATA_PATH ))\n",
    "\n",
    "fnames = fnames[1:4]\n",
    "\n",
    "no = list()\n",
    "f1 = list()\n",
    "f2 = list()\n",
    "q1 = list()\n",
    "q2 = list()\n",
    "\n",
    "for fname in fnames:\n",
    "    print(fname)\n",
    "\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH,fname), usecols = ['ds', 'y'])[-60:]\n",
    "    df['y'] = pd.to_numeric(df['y'])\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "#     beta = df.loc[df['y'] > np.quantile(df.y,0.95), 'y'].mean()/df.loc[df['y'] < np.quantile(df.y,0.95), 'y'].mean()\n",
    "    beta = 1.5\n",
    "    \n",
    "    rn = [1,2,3,4,5,6,7,8,9,10]\n",
    "    for r in rn:\n",
    "        a, b, c, d, e = set_random(r, df, 3, beta - 0.2, beta, beta + 0.2, 0.94, 0.96)\n",
    "    \n",
    "        no.append(a)\n",
    "        f1.append(b)\n",
    "        f2.append(c)\n",
    "        q1.append(d)\n",
    "        q2.append(e)\n",
    "    \n",
    "#     print(np.mean(a, axis = 1))\n",
    "\n",
    "    print( \"\\n ====================================\")\n",
    "    #rn, dev_avg, beta_min, beta, beta_max , q_min, q_max\n",
    "\n",
    "print(\"without cutoff: \", np.mean(no), np.std(no))\n",
    "print(\"fixed beta: \", np.mean(f1), np.std(f1))\n",
    "print(\"adaptive: \", np.mean(f2), np.std(f2))\n",
    "print(\"q\", np.mean(q1), np.std(q1))\n",
    "print(\"adap_q\", np.mean(q2), np.std(q2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing beta as 1.5 or 2 sometimes is better than setting beta depending on outlier_extremity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depending on number of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rn = [1,2,3,4,5,6,7,8,9,10]\n",
    "for r in rn:\n",
    "    df = pd.read_csv('data/2logistics.csv', usecols = ['ds', 'y'])[-90 * r:]\n",
    "    df['y'] = pd.to_numeric(df['y'])\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    beta = df.loc[df['y'] > np.quantile(df.y,0.95), 'y'].mean()/df.loc[df['y'] < np.quantile(df.y,0.95), 'y'].mean()\n",
    "#         print(set_random(r, 3, 1.8, 2, 2.2, 0.94, 0.96))\n",
    "#         a.append(list(*set_random(r, 3, 1.8, 2, 2.2, 0.94, 0.96)))\n",
    "#     a, b, c, d, e = set_random(r, df, 3, 1.8, 2, 2.2, 0.94, 0.96)\n",
    "    a, b, c, d, e = set_random(r, df, 3, beta - 0.2, beta, beta + 0.2, 0.94, 0.96)\n",
    "    no.append(a)\n",
    "    f1.append(b)\n",
    "    f2.append(c)\n",
    "    q1.append(d)\n",
    "    q2.append(e)\n",
    "\n",
    "#     print(np.mean(a, axis = 1))\n",
    "\n",
    "print( \"\\n ====================================\")\n",
    "#rn, dev_avg, beta_min, beta, beta_max , q_min, q_max\n",
    "\n",
    "print(\"without cutoff: \", np.mean(no), np.std(no))\n",
    "print(\"fixed beta: \", np.mean(f1), np.std(f1))\n",
    "print(\"adaptive: \", np.mean(f2), np.std(f2))\n",
    "print(\"q\", np.mean(q1), np.std(q1))\n",
    "print(\"adap_q\", np.mean(q2), np.std(q2))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
